{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis of attention\n",
    "\n",
    "This notebooks dives into the attention layers of the model and looks of explanations of predictions. Furthermore, it seeks to understand if there is the expected connections between "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uses the bertviz lib\n",
    "\n",
    "Please note that the output os written to files because the size crashes most notebooks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model View\n",
    "<b>The model view provides a birds-eye view of attention throughout the entire model</b>. Each cell shows the attention weights for a particular head, indexed by layer (row) and head (column).  The lines in each cell represent the attention from one token (left) to another (right), with line weight proportional to the attention value (ranges from 0 to 1).  For a more detailed explanation, please refer to the [blog](https://towardsdatascience.com/deconstructing-bert-part-2-visualizing-the-inner-workings-of-attention-60a16d86b5c1).\n",
    "\n",
    "## Usage\n",
    "ðŸ‘‰ **Click** on any **cell** for a detailed view of attention for the associated attention head (or to unselect that cell). <br/>\n",
    "ðŸ‘‰ Then **hover** over any **token** on the left side of detail view to filter the attention from that token."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "________________________________________________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Head View\n",
    "<b>The head view visualizes attention in one or more heads from a single Transformer layer.</b> Each line shows the attention from one token (left) to another (right). Line weight reflects the attention value (ranges from 0 to 1), while line color identifies the attention head. When multiple heads are selected (indicated by the colored tiles at the top), the corresponding  visualizations are overlaid onto one another.  For a more detailed explanation of attention in Transformer models, please refer to the [blog](https://towardsdatascience.com/deconstructing-bert-part-2-visualizing-the-inner-workings-of-attention-60a16d86b5c1).\n",
    "\n",
    "## Usage\n",
    "ðŸ‘‰ **Hover** over any **token** on the left/right side of the visualization to filter attention from/to that token. <br/>\n",
    "ðŸ‘‰ **Double-click** on any of the **colored tiles** at the top to filter to the corresponding attention head.<br/>\n",
    "ðŸ‘‰ **Single-click** on any of the **colored tiles** to toggle selection of the corresponding attention head. <br/>\n",
    "ðŸ‘‰ **Click** on the **Layer** drop-down to change the model layer (zero-indexed).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SQUAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer:  9th century\n",
      " 13.574966430664062\n"
     ]
    }
   ],
   "source": [
    "# Squad\n",
    "from transformers import RobertaModel, RobertaTokenizer, AutoModelForQuestionAnswering, AutoTokenizer\n",
    "from bertviz import head_view, model_view\n",
    "import torch\n",
    "\n",
    "\n",
    "model_version = 'deepset/roberta-base-squad2'\n",
    "model = AutoModelForQuestionAnswering.from_pretrained(model_version, output_attentions=True)\n",
    "tokenizer = RobertaTokenizer.from_pretrained(model_version)\n",
    "\n",
    "sentence_b = \"\"\"The English name \"Normans\" comes from the French words Normans/Normanz, plural of Normant, modern French normand, which is itself borrowed from Old Low Franconian Nortmann \"Northman\" or directly from Old Norse NorÃ°maÃ°r, Latinized variously as Nortmannus, Normannus, or Nordmannus (recorded in Medieval Latin, 9th century) to mean \"Norseman, Viking\".\"\"\"\n",
    "sentence_a = 'When was the Latin version of the word Norman first recorded?'\n",
    "inputs = tokenizer.encode_plus(sentence_a, sentence_b, return_tensors='pt', add_special_tokens=True)\n",
    "input_ids = inputs['input_ids']\n",
    "outputs=model(input_ids)\n",
    "attention = outputs[-1]\n",
    "input_id_list = input_ids[0].tolist() # Batch index 0\n",
    "\n",
    "tokens = tokenizer.convert_ids_to_tokens(input_id_list)\n",
    "answer_start_scores, answer_end_scores = outputs.start_logits, outputs.end_logits\n",
    "answer_start = torch.argmax(\n",
    "    answer_start_scores\n",
    ")  # Get the most likely beginning of answer with the argmax of the score\n",
    "answer_end = torch.argmax(answer_end_scores) + 1  # Get the most likely end of answer with the argmax of the score\n",
    "answer = tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(input_ids.squeeze()[answer_start:answer_end]))\n",
    "\n",
    "print(f\"Answer: {answer}\\n {answer_start_scores.max().tolist()+answer_end_scores.max().tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When was the Latin version of the word Norman first recorded?\n",
      "The English name \"Normans\" comes from the French words Normans/Normanz, plural of Normant, modern French normand, which is itself borrowed from Old Low Franconian Nortmann \"Northman\" or directly from Old Norse NorÃ°maÃ°r, Latinized variously as Nortmannus, Normannus, or Nordmannus (recorded in Medieval Latin, 9th century) to mean \"Norseman, Viking\".\n"
     ]
    }
   ],
   "source": [
    "print(sentence_a)\n",
    "print(sentence_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "html_data = head_view(attention, tokens, input_id_list.index(2), html_action='return')\n",
    "with open(\"./Figures_For_report/head_view_squad.html\", 'w') as file:\n",
    "    file.write(html_data.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "html_data = model_view(attention, tokens, input_id_list.index(2), html_action='return', include_layers=[10,11])\n",
    "with open(\"./Figures_For_report/model_view_squad.html\", 'w') as file:\n",
    "    file.write(html_data.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CUAD\n",
    "\n",
    "For ease of use the CUAD checkpoint is used, but this should be checkpoint from the thesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer:  DISTRIBUTOR AGREEMENT\n",
      " 11.496758460998535\n"
     ]
    }
   ],
   "source": [
    "model_version = 'Rakib/roberta-base-on-cuad'\n",
    "model = AutoModelForQuestionAnswering.from_pretrained(model_version, output_attentions=True)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_version)\n",
    "\n",
    "sentence_b = \"EXHIBIT 10.6 DISTRIBUTOR AGREEMENT THIS DISTRIBUTOR AGREEMENT is made by and between Electric City Corp., a Delaware corporation ('Company') and Electric City of Illinois LLC ('Distributor') this 7th day of September, 1999\"+ \"A. The  Company's  Business.  The Company is  presently  engaged in the business  of selling an energy  efficiency  device\"\n",
    "sentence_a = 'Highlight the parts (if any) of this contract related to \"Document Name\" that should be reviewed by a lawyer. Details: The name of the contract'\n",
    "inputs = tokenizer.encode_plus(sentence_a, sentence_b, return_tensors='pt', add_special_tokens=True)\n",
    "input_ids = inputs['input_ids']\n",
    "outputs=model(input_ids)\n",
    "attention = outputs[-1]\n",
    "input_id_list = input_ids[0].tolist() # Batch index 0\n",
    "\n",
    "tokens = tokenizer.convert_ids_to_tokens(input_id_list)\n",
    "answer_start_scores, answer_end_scores = outputs.start_logits, outputs.end_logits\n",
    "answer_start = torch.argmax(\n",
    "    answer_start_scores\n",
    ")  # Get the most likely beginning of answer with the argmax of the score\n",
    "answer_end = torch.argmax(answer_end_scores) + 1  # Get the most likely end of answer with the argmax of the score\n",
    "answer = tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(input_ids.squeeze()[answer_start:answer_end]))\n",
    "\n",
    "print(f\"Answer: {answer}\\n {answer_start_scores.max().tolist()+answer_end_scores.max().tolist()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "html_data = head_view(attention, tokens, input_id_list.index(2), html_action='return')\n",
    "with open(\"./Figures_For_report/head_view_cuad.html\", 'w') as file:\n",
    "    file.write(html_data.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "html_data = model_view(attention, tokens, input_id_list.index(2), html_action='return')\n",
    "with open(\"./Figures_For_report/model_view_cuad.html\", 'w') as file:\n",
    "    file.write(html_data.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Legal bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at nlpaueb/legal-bert-base-uncased were not used when initializing BertForQuestionAnswering: ['cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForQuestionAnswering were not initialized from the model checkpoint at nlpaueb/legal-bert-base-uncased and are newly initialized: ['qa_outputs.weight', 'qa_outputs.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This model is not fine-tuned for QA\n"
     ]
    }
   ],
   "source": [
    "model_version = 'nlpaueb/legal-bert-base-uncased'\n",
    "model = AutoModelForQuestionAnswering.from_pretrained(model_version, output_attentions=True)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_version)\n",
    "\n",
    "sentence_b = \"EXHIBIT 10.6 DISTRIBUTOR AGREEMENT THIS DISTRIBUTOR AGREEMENT is made by and between Electric City Corp., a Delaware corporation ('Company') and Electric City of Illinois LLC ('Distributor') this 7th day of September, 1999\"+ \"A. The  Company's  Business.  The Company is  presently  engaged in the business  of selling an energy  efficiency  device\"\n",
    "sentence_a = 'Highlight the parts (if any) of this contract related to \"Document Name\" that should be reviewed by a lawyer. Details: The name of the contract'\n",
    "inputs = tokenizer.encode_plus(sentence_a, sentence_b, return_tensors='pt', add_special_tokens=True)\n",
    "input_ids = inputs['input_ids']\n",
    "outputs=model(input_ids)\n",
    "attention = outputs[-1]\n",
    "input_id_list = input_ids[0].tolist() # Batch index 0\n",
    "tokens = tokenizer.convert_ids_to_tokens(input_id_list)\n",
    "\n",
    "print(\"This model is not fine-tuned for QA\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Highlight the parts (if any) of this contract related to \"Document Name\" that should be reviewed by a lawyer. Details: The name of the contract\n",
      "EXHIBIT 10.6 DISTRIBUTOR AGREEMENT THIS DISTRIBUTOR AGREEMENT is made by and between Electric City Corp., a Delaware corporation ('Company') and Electric City of Illinois LLC ('Distributor') this 7th day of September, 1999A. The  Company's  Business.  The Company is  presently  engaged in the business  of selling an energy  efficiency  device\n"
     ]
    }
   ],
   "source": [
    "print(sentence_a)\n",
    "print(sentence_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "html_data = head_view(attention, tokens, input_id_list.index(102), html_action='return')\n",
    "with open(\"./Figures_For_report/head_view_legal.html\", 'w') as file:\n",
    "    file.write(html_data.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f263b30b47212596c6dca0cd91fb0c51f07ee748dab3d0cfddddb639cf5b7790"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('test4')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
